{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prelims\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math, time\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from keras.datasets import imdb\n",
    "\n",
    "from rnn import RNN"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>\n",
    "<img src=\"https://stanford.edu/~shervine/teaching/cs-230/illustrations/architecture-rnn-ltr.png?9ea4417fc145b9346a3e288801dbdfdc\" width=\"800\"/>\n",
    "</div>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TESTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, training loss: 1.4667165699747788\n",
      "Epoch 2, training loss: 1.455980251851398\n",
      "Epoch 3, training loss: 1.4452723907056724\n",
      "Epoch 4, training loss: 1.434454872584022\n",
      "Epoch 5, training loss: 1.423383039124447\n",
      "Epoch 6, training loss: 1.4119031180497468\n",
      "Epoch 7, training loss: 1.3998511155225049\n",
      "Epoch 8, training loss: 1.387065534782919\n",
      "Epoch 9, training loss: 1.3733692842295198\n",
      "Epoch 10, training loss: 1.358423010590644\n",
      "Epoch 11, training loss: 1.3423450367674967\n",
      "Epoch 12, training loss: 1.325082799335659\n",
      "Epoch 13, training loss: 1.3064898650505519\n",
      "Epoch 14, training loss: 1.2864152210408415\n",
      "Epoch 15, training loss: 1.26468831436911\n",
      "Epoch 16, training loss: 1.2412999807794038\n",
      "Epoch 17, training loss: 1.216207276966697\n",
      "Epoch 18, training loss: 1.1893176615094916\n",
      "Epoch 19, training loss: 1.160614442306576\n",
      "Epoch 20, training loss: 1.1302091653125252\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from rnn import RNN\n",
    "import numpy as np\n",
    "\n",
    "vocab_size = 5\n",
    "\n",
    "###\n",
    "seq1 = np.zeros((3,vocab_size,1))\n",
    "s1 = [0,2,4]\n",
    "\n",
    "for i,val in enumerate(s1):\n",
    "    seq1[i][val] = 1\n",
    "\n",
    "y1 = np.zeros((2,1))\n",
    "y1[0] = 1\n",
    "\n",
    "\n",
    "###\n",
    "seq2 = np.zeros((4,vocab_size,1))\n",
    "s2 = [1,3,2,0]\n",
    "\n",
    "for i,val in enumerate(s2):\n",
    "    seq2[i][val] = 1\n",
    "\n",
    "y2 = np.zeros((2,1))\n",
    "y2[1] = 1\n",
    "\n",
    "###\n",
    "seq3 = np.zeros((3,vocab_size,1))\n",
    "s3 = [0,3,1]\n",
    "\n",
    "for i,val in enumerate(s3):\n",
    "    seq3[i][val] = 1\n",
    "\n",
    "y3 = np.zeros((2,1))\n",
    "y3[0] = 1\n",
    "\n",
    "Xtrain = [seq1, seq2]\n",
    "Ytrain = [y1, y2]\n",
    "\n",
    "Xtest = [seq3]\n",
    "Ytest = [y3]\n",
    "\n",
    "rnntest = RNN(input_dim=vocab_size, output_dim=2, hidden_dim=5, learning_rate=.01)\n",
    "rnntest.fit(Xtrain, Ytrain, num_epochs=20)\n",
    "\n",
    "rnntest.evaluate(Xtest, Ytest)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation on IMDB Dataset\n",
    "\n",
    "Words are indexed by overall frequency in the dataset e.g. `3` encodes the third most frequent word.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import imdb\n",
    "import numpy as np\n",
    "vocab_size = 100\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=vocab_size)\n",
    "\n",
    "word_index = imdb.get_word_index()\n",
    "index_to_word = dict([(value,key) for (key,value) in word_index.items()])\n",
    "\n",
    "(X_train_small, y_train_small) = (X_train[0:100], y_train[0:100])\n",
    "(X_test_small, y_test_small) = (X_test[0:100], y_test[0:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode(input):\n",
    "    sentence = []\n",
    "    for i in input:\n",
    "        sentence.append(index_to_word.get(i-3, '!'))\n",
    "    print(\" \".join(sentence))\n",
    "    return sentence\n",
    "\n",
    "def one_hot(value, vec_size):\n",
    "    \"\"\"\n",
    "    Given a scalar returns the one-hot encoding vector.\n",
    "    \"\"\"\n",
    "    # initialize input matrix\n",
    "    x = np.zeros((vec_size, 1))\n",
    "    x[value] = 1\n",
    "        \n",
    "    return x\n",
    "\n",
    "def subtract_one(X):\n",
    "    \"\"\"\n",
    "    Subtracts one from each value.\n",
    "    \"\"\"\n",
    "    for i in range(X.size):\n",
    "        X[i] = [x-1 for x in X[i]]\n",
    "    \n",
    "    return X\n",
    "\n",
    "def one_hot_x(X):\n",
    "    oh = [None] * X.size\n",
    "    for i, input in enumerate(X):\n",
    "        xx = np.zeros((len(input), vocab_size, 1))\n",
    "        for j, val in enumerate(input):\n",
    "            xx[j][val] = 1\n",
    "        oh[i] = xx\n",
    "    \n",
    "    return oh\n",
    "\n",
    "def one_hot_y(Y):\n",
    "    oh = [None] * Y.size\n",
    "    for i, y in enumerate(Y):\n",
    "        oh[i] = one_hot(y, 2)\n",
    "    \n",
    "    return oh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subtract ones\n",
    "X_train_small = subtract_one(X_train_small)\n",
    "X_test_small = subtract_one(X_test_small)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "tx = one_hot_x(X_train_small)\n",
    "ty = one_hot_y(y_train_small)\n",
    "testingx = one_hot_x(X_test_small)\n",
    "testingy = one_hot_y(y_test_small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, training loss: 38.02021500786034\n",
      "Epoch 2, training loss: 37.88570052221522\n",
      "Epoch 3, training loss: 37.76739698482241\n",
      "Epoch 4, training loss: 37.66479923610425\n",
      "Epoch 5, training loss: 37.57031353036847\n",
      "Epoch 6, training loss: 37.48792986875993\n",
      "Epoch 7, training loss: 37.406753961560895\n",
      "Epoch 8, training loss: 37.32507970195589\n",
      "Epoch 9, training loss: 37.24167319569322\n",
      "Epoch 10, training loss: 37.158977623183155\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[38.02021500786034,\n",
       " 37.88570052221522,\n",
       " 37.76739698482241,\n",
       " 37.66479923610425,\n",
       " 37.57031353036847,\n",
       " 37.48792986875993,\n",
       " 37.406753961560895,\n",
       " 37.32507970195589,\n",
       " 37.24167319569322,\n",
       " 37.158977623183155]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from rnn import RNN\n",
    "RNNModel = RNN(input_dim=vocab_size, hidden_dim=10, output_dim=2, learning_rate=1e-4)\n",
    "RNNModel.fit(tx, ty, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.43"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RNNModel.evaluate(testingx, testingy)\n",
    "# RNNModel.evaluate(tx, ty)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
